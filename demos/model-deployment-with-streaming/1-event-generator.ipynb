{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Event Generator\n",
    "  --------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate an events stream to simulate incoming data. In real life situations you will provide input data instead of this simulated data.\n",
    "\n",
    "The output is a stream of events called `generated-stream`.\n",
    "\n",
    "![Model deployment with streaming Real-time operational Pipeline](../../assets/images/model-deployment-with-streaming.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faker in /User/.pythonlibs/jupyter-mk/lib/python3.6/site-packages (4.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.4 in /conda/lib/python3.6/site-packages (from faker) (2.8.1)\n",
      "Requirement already satisfied: text-unidecode==1.3 in /User/.pythonlibs/jupyter-mk/lib/python3.6/site-packages (from faker) (1.3)\n",
      "Requirement already satisfied: six>=1.5 in /conda/lib/python3.6/site-packages (from python-dateutil>=2.4->faker) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "# We use the faker module to generate data, please run this cell and restart the notenook's kernel.\n",
    "import sys\n",
    "!{sys.executable} -m pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint, random\n",
    "import math\n",
    "import v3io.dataplane\n",
    "from faker import Faker\n",
    "import uuid\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "STREAM_PATH =  STREAM_CONFIGS['generated-stream']['path']\n",
    "SHARDS_COUNT = STREAM_CONFIGS['generated-stream']['shard_count']\n",
    "\n",
    "\n",
    "def gen_postcode(is_churn):\n",
    "    # if is_churn is true the postcode modulu 3 will return 0 or 1\n",
    "    # if is_churn is false the postcode modulu 3 will return 0 or 2\n",
    "    # this will encode information in postcode that our ML model will learn\n",
    "    base_postcode = 3 * randint(3334,33333)\n",
    "    group = randint(0,1)\n",
    "    if is_churn:\n",
    "        return base_postcode + group\n",
    "    else:\n",
    "        return base_postcode + (group * 2)\n",
    "\n",
    "# event functions\n",
    "def new_registration(fake, id, event_time, is_churn):\n",
    "    return {'user_id': id,\n",
    "            'event_type': 'registration',\n",
    "            'event_time': event_time,\n",
    "            'name':fake.name(),\n",
    "            'date_of_birth': fake.date(),\n",
    "            'street_address': fake.street_address(),\n",
    "            'city': fake.city(),\n",
    "            'country': fake.country(),\n",
    "            'postcode': gen_postcode(is_churn),\n",
    "            'affiliate_url': fake.image_url(),\n",
    "            'campaign': fake.ean8()}\n",
    "\n",
    "def new_purchase(fake, id, event_time):\n",
    "    return {'user_id': id,\n",
    "            'event_type': 'purchase',\n",
    "            'event_time': event_time,\n",
    "            'amount': fake.randomize_nb_elements(number=50)}\n",
    "\n",
    "def new_bet(fake, id, event_time):\n",
    "    return {'user_id': id,\n",
    "            'event_type': 'bet',\n",
    "            'event_time': event_time,\n",
    "            'bet_amount': fake.randomize_nb_elements(number=10)}\n",
    "    \n",
    "def new_win(fake, id, event_time):\n",
    "    return {'user_id': id,\n",
    "            'event_type': 'win',\n",
    "            'event_time': event_time,\n",
    "            'win_amount': fake.randomize_nb_elements(number=200)}\n",
    "\n",
    "def gen_event_date(is_churn, prev_event_date=None):\n",
    "    if prev_event_date is None:\n",
    "        #generate first event date\n",
    "        return str(datetime.now() - timedelta(hours=randint(48,96)))\n",
    "    else:\n",
    "        prev_dt = datetime.strptime(prev_event_date,'%Y-%m-%d %H:%M:%S.%f')\n",
    "        if prev_dt + timedelta(hours=30) < datetime.now() and not is_churn and randint(1,1000) <= 5:\n",
    "            # if the user is not churned and it is possible, generate event in the following day with prbability 0.005\n",
    "            return str(prev_dt + timedelta(hours=randint(15,24)))\n",
    "        else:\n",
    "            return str(prev_dt + timedelta(seconds=randint(5,100)))\n",
    "        \n",
    "def generate_events(fake, user_ids, events_dist, num_events, is_churn):\n",
    "    events = []\n",
    "    for id in user_ids:\n",
    "        # register\n",
    "        event_time = gen_event_date(is_churn)\n",
    "        reg_event = new_registration(fake, id, event_time, is_churn)\n",
    "        reg_event['label'] = int(is_churn)\n",
    "        events.append(reg_event)\n",
    "        for _ in range(num_events):\n",
    "            # generate event according to dist\n",
    "            acc_prob = 0\n",
    "            rand = random()\n",
    "            for event_dist in events_dist:\n",
    "                if rand <= event_dist['probability']+acc_prob:\n",
    "                    event_time = gen_event_date(is_churn, event_time)\n",
    "                    new_event = event_dist['generator'](fake, id, event_time)\n",
    "                    events.append(new_event)\n",
    "                    prob_threshold = 0\n",
    "                    break\n",
    "                else:\n",
    "                    acc_prob += event_dist['probability']\n",
    "    return events\n",
    "\n",
    "\n",
    "# 70% churn users \n",
    "NUM_USERS_GROUP1 = 1400\n",
    "NUM_USERS_GROUP2 = 600 \n",
    "NUM_USERS = NUM_USERS_GROUP1+NUM_USERS_GROUP2\n",
    "\n",
    "EVENTS_PER_USER = 1000\n",
    "\n",
    "GROUP1_EVENTS_DIST = [{'probability': 0.1, 'generator': new_purchase}, \n",
    "                      {'probability': 0.89, 'generator': new_bet}, \n",
    "                      {'probability': 0.01, 'generator': new_win}]\n",
    "\n",
    "GROUP2_EVENTS_DIST = [{'probability': 0.1, 'generator': new_purchase}, \n",
    "                      {'probability': 0.85, 'generator': new_bet},\n",
    "                      {'probability': 0.05, 'generator': new_win}]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create V3IO Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "v3io_client = v3io.dataplane.Client(endpoint='http://v3io-webapi:8081', access_key=V3IO_ACCESS_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Events generated: 2002000\n",
      "Events preview: [{'user_id': '5c67790a-29e2-455f-b67c-a8f67da54c2c', 'event_type': 'bet', 'event_time': '2020-08-06 21:42:29.770807', 'bet_amount': 11}, {'user_id': '5c67790a-29e2-455f-b67c-a8f67da54c2c', 'event_type': 'bet', 'event_time': '2020-08-06 21:44:08.770807', 'bet_amount': 11}, {'user_id': '5c67790a-29e2-455f-b67c-a8f67da54c2c', 'event_type': 'bet', 'event_time': '2020-08-06 21:44:42.770807', 'bet_amount': 12}, {'user_id': '5c67790a-29e2-455f-b67c-a8f67da54c2c', 'event_type': 'bet', 'event_time': '2020-08-06 21:45:49.770807', 'bet_amount': 10}]\n"
     ]
    }
   ],
   "source": [
    "fake = Faker()\n",
    "\n",
    "group1_user_ids = (str(uuid.uuid4()) for _ in range(NUM_USERS_GROUP1))\n",
    "group2_user_ids = (str(uuid.uuid4()) for _ in range(NUM_USERS_GROUP2))\n",
    "\n",
    "group1_events = generate_events(fake, group1_user_ids, GROUP1_EVENTS_DIST, EVENTS_PER_USER, True)\n",
    "group2_events = generate_events(fake, group2_user_ids, GROUP2_EVENTS_DIST, EVENTS_PER_USER, False)\n",
    "\n",
    "\n",
    "print(f'Events generated: {len(group1_events)+len(group2_events)}')\n",
    "print(f'Events preview: {group1_events[1:5]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write generated events to V3IO Steam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform the event to stream records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = (group1_events + group2_events)\n",
    "events.sort(key=lambda event: datetime.strptime(event.get('event_time'), '%Y-%m-%d %H:%M:%S.%f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = [{'data': json.dumps(event)} for event in events]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ingest in small batches to V3IO Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-09 10:44:03,931 [info] Disconnected while attempting to send. Recreating connection: {'e': <class 'BrokenPipeError'>}\n",
      "2020-08-09 10:44:03,950 [info] Disconnected while attempting to send. Recreating connection: {'e': <class 'BrokenPipeError'>}\n",
      "2020-08-09 10:44:03,968 [info] Disconnected while attempting to send. Recreating connection: {'e': <class 'BrokenPipeError'>}\n",
      "2020-08-09 10:44:03,984 [info] Disconnected while attempting to send. Recreating connection: {'e': <class 'BrokenPipeError'>}\n",
      "2020-08-09 10:44:03,999 [info] Disconnected while attempting to send. Recreating connection: {'e': <class 'BrokenPipeError'>}\n",
      "2020-08-09 10:44:04,014 [info] Disconnected while attempting to send. Recreating connection: {'e': <class 'BrokenPipeError'>}\n",
      "2020-08-09 10:44:04,029 [info] Disconnected while attempting to send. Recreating connection: {'e': <class 'BrokenPipeError'>}\n",
      "2020-08-09 10:44:04,045 [info] Disconnected while attempting to send. Recreating connection: {'e': <class 'BrokenPipeError'>}\n",
      "Successfully streamed 2002000, failed to stream 0\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "streamed_records = 0\n",
    "failed_records = 0\n",
    "for i in range(0, len(records), batch_size):\n",
    "    resp = v3io_client.put_records(container=CONTAINER, path=STREAM_PATH, records=records[i:i+batch_size])\n",
    "    streamed_records += len(json.loads(resp.body)['Records'])\n",
    "    failed_records += json.loads(resp.body)['FailedRecordCount']\n",
    "print(f'Successfully streamed {streamed_records}, failed to stream {failed_records}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

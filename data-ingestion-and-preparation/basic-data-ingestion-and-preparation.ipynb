{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Data Ingestion and Preparation\n",
    "\n",
    "Learn how to quickly start using the Iguazio Data Science Platform to collect, ingest, and explore data.\n",
    "\n",
    "- [Overview](#gs-overview)\n",
    "  - [Platform Data Containers](#platform-data-containers)\n",
    "- [Collecting and Ingesting Data](#gs-data-collection-and-ingestion)\n",
    "  - [Ingesting Data From an External Database to a NoSQL Table Using V3IO Frames](#ingest-from-external-db-to-no-sql-using-frames)\n",
    "  - [Ingesting Files from Amazon S3](#ingest-from-amazon-s3)\n",
    "  - [Streaming Data From an External Streaming Engine Using Nuclio](#streaming-data-from-an-external-streaming-engine-using-nuclio)\n",
    "- [Exploring and Processing Data](#gs-data-exploration-and-processing)\n",
    "  - [Exploring Data Using Spark DataFrames](#data-exploration-spark)\n",
    "  - [Exploring Data Using V3IO Frames and pandas DataFrames](#data-exploration-v3io-frames-n-pandas)\n",
    "  - [Exploring Data Using SQL](#data-exploration-sql)\n",
    "- [Data Collection and Exploration Getting-Started Example](#getting-started-example)\n",
    "  - [Step 1: Ingest a Sample CSV File from Amazon S3](#getting-started-example-step-ingest-csv)\n",
    "  - [Step 2: Convert the Sample CSV File to a NoSQL Table](#getting-started-example-step-convert-csv-to-nosql-table)\n",
    "  - [Step 3: Run Interactive SQL Queries](#getting-started-example-step-run-sql-queries)\n",
    "  - [Step 4: Convert the Data to a Parquet Table](#getting-started-example-step-convert-data-to-parquet)\n",
    "  - [Step 5: Browse the Example Container Directory](#getting-started-example-step-browse-the-examples-dir)\n",
    "- [Cleanup](#cleanup)\n",
    "  - [Delete Data](#delete-data)\n",
    "  - [Release Spark Resources](#release-spark-resources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gs-overview\"></a>\n",
    "## Overview\n",
    "\n",
    "This tutorial explains and demonstrates how to collect, ingest, and explore data with the Iguazio Data Science Platform (**\"the platform\"**).<br>\n",
    "For an in-depth overview of the platform and how it can be used to implement a full data science workflow, see the [**platform-overview.ipynb**](../platform-overview.ipynb) tutorial notebook.<br>\n",
    "For full end-to-end platform use-case application demos, see [**demos**](../demos/README.ipynb) tutorial notebooks directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"platform-data-containers\"></a>\n",
    "### Platform Data Containers\n",
    "\n",
    "Data is stored within data containers in the platform's distributed file system (DFS).\n",
    "All platform clusters have two predefined containers:\n",
    "\n",
    "- <a id=\"default-container\"></a> The default **\"bigdata\"** container.\n",
    "- <a id=\"users-container\"></a>The **\"users\"** container, which is designed to contain **&lt;username&gt;** directories that provide individual development environments for storing user-specific data.\n",
    "  The platform's Jupyter Notebook, Zeppelin, and web-based shell \"command-line services\" automatically create such a directory for the running user of the service and set it as the home directory of the service environment.\n",
    "  You can leverage the following environment variables, which are predefined in the platform's command-line services, to access this running-user directory from your code:\n",
    "\n",
    "  - `V3IO_USERNAME` &mdash; set to the username of the running user of the Jupyter Notebook service.\n",
    "  - `V3IO_HOME` &mdash; set to the running-user directory in the \"users\" container &mdash; **users/&lt;running user&gt;**.\n",
    "  - `V3IO_HOME_URL` &mdash; set to the fully qualified `v3io` path to the running-user directory &mdash; `v3io://users/<running user>`.\n",
    "\n",
    "The data containers and their contents are referenced differently depending on the programming interface.\n",
    "For example:\n",
    "\n",
    "- In local file-system (FS) commands you use the predefined `v3io` root data mount &mdash; `/v3io/<container name>[/<data path>]`.\n",
    "  There's also a predefined local-FS `User` mount to the **users/&lt;running user&gt;** directory, and you can use the aforementioned environment variables when setting data paths.\n",
    "  For example, `/v3io/users/$V3IO_USERNAME`, `/v3io/$V3IO_HOME`, and `/User` are all valid ways of referencing the **users/&lt;running user&gt;** directory from a local FS command.\n",
    "- In Hadoop FS or Spark DataFrame commands you use a fully qualified path of the format `v3io://<container name>/<data path>`.\n",
    "  You can also use environment variables with these interfaces.\n",
    "\n",
    "For detailed information and examples on how to set the data path for each interface, see [Setting Data Paths](https://www.iguazio.com/docs/latest-release/tutorials/getting-started/fundamentals/#data-paths) and the examples in the platform's tutorial Jupyter notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gs-data-collection-and-ingestion\"></a>\n",
    "## Collecting and Ingesting Data\n",
    "\n",
    "The platform supports various alternative methods for collecting and ingesting data into its data containers (i.e., its data store).\n",
    "For more information, see the [**platform-overview.ipynb**](../platform-overview.ipynb.ipynb#data-collection-and-ingestion) tutorial notebook\n",
    "The data collection and ingestion can be done as a one-time operation, using different platform APIs &mdash; which can be run from your preferred programming interface, such as an interactive web-based Jupyter or Zeppelin notebook &mdash; or as an ongoing ingestion stream, using Nuclio serverless functions.\n",
    "This section explains and demonstrates how to collect and ingest (import) data into the platform using code that's run from a Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ingest-from-external-db-to-no-sql-using-frames\"></a>\n",
    "### Ingesting Data From an External Database to a NoSQL Table Using V3IO Frames\n",
    "\n",
    "For an example of how to collect data from an external database &mdash; such as MySQL, Oracle, and PostgreSQL &mdash; and ingest (write) it into a NoSQL table in the platform, using the V3IO Frames API, see the [read-external-db](read-external-db.ipynb) tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ingest-from-amazon-s3\"></a>\n",
    "### Ingesting Files from Amazon S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ingest-from-amazon-s3-using-curl\"></a>\n",
    "#### Ingesting Files from Amazon S3 to the Platform File System Using curl\n",
    "\n",
    "You can use a simple [curl](https://curl.haxx.se/) command to ingest a file (object) from an external web data source, such as an Amazon S3 bucket, to the platform's distributed file system (i.e., into the platform's data store).\n",
    "This is demonstrated in the following code example and in the [getting-started example](#getting-started-example) in this notebook.\n",
    "The [spark-sql-analytics](spark-sql-analytics.ipynb) tutorial notebook demonstrates a similar ingestion using [Botocore](https://github.com/boto/botocore).\n",
    "\n",
    "The example in the following cells uses curl to read a CSV file from the [Iguazio sample data-sets](http://iguazio-sample-data.s3.amazonaws.com/) public Amazon S3 bucket and save it to an **examples** directory in the running-user directory of the predefined \"users\" data container (`/v3io/users/$V3IO_USERNAME` = `v3io/$V3IO_HOME` = `/User`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /User/examples # <=> /v3io/${V3IO_HOME}/examples or /v3io/users/${V3IO_USERNAME}/examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  861k  100  861k    0     0   493k      0  0:00:01  0:00:01 --:--:--  493k\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "CSV_PATH=\"/User/examples/stocks.csv\"\n",
    "curl -L \"iguazio-sample-data.s3.amazonaws.com/2018-03-26_BINS_XETR08.csv\" > ${CSV_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ingest-from-amazon-s3-to-nosql-table-using-v3io-frames-n-pandas\"></a>\n",
    "#### Ingesting Data from Amazon S3 to a NoSQL Table Using V3IO Frames and pandas\n",
    "\n",
    "For an example of how to import data from Amazon S3 and save it into a NoSQL table in the platform's data store by using V3IO Frames and pandas DataFrames, see the [frames](frames.ipynb) tutorial notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"streaming-data-from-an-external-streaming-engine-using-nuclio\"></a>\n",
    "### Streaming Data From an External Streaming Engine Using Nuclio\n",
    "\n",
    "To read data from an external streaming engine &mdash; such as Kafka, Kinesis, or RabbitMQ &mdash; create a Nuclio function that listens on the stream, and write the stream data to a NoSQL or time-series database (TSDB) table:\n",
    "\n",
    "1. In the dashboard's side navigation menu, select **Functions** to display the Nuclio serverless functions dashboard.\n",
    "2. Create a new Nuclio project or select an existing project.\n",
    "3. In the action toolbar, select **Create Function**.\n",
    "4. Enter a function name, select an appropriate template, such as **kafka-to-tsdb**, configure the required template parameters, and apply your changes.\n",
    "5. Select **Deploy** from the action toolbar to deploy your function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gs-data-exploration-and-processing\"></a>\n",
    "## Exploring and Processing Data\n",
    "\n",
    "After you have ingested data into the platform's data containers, you can use various alternative methods and tools to explore and analyze the data.\n",
    "Data scientists typically use Jupyter Notebook to run the exploration phase.\n",
    "As outlined in the [**welcome**](../welcome.ipynb#data-exploration-and-processing) tutorial notebook, the platform's Jupyter Notebook service has a wide range of pre-deployed popular data science tools (such as Spark and Presto) and allows installation of additional tools and packages, enabling you to use different APIs to access the same data from a single Jupyter notebook.\n",
    "This section explains and demonstrates how to explore data in the platform from a Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data-exploration-spark\"></a>\n",
    "### Exploring Data using Spark DataFrames\n",
    "\n",
    "Spark is a distributed computing framework for data analytics.\n",
    "You can easily run distributed Spark jobs on you platform cluster that use Spark DataFrames to access data files (objects), tables, or streams in the platform's data store.\n",
    "For more information and examples, see the [spark-sql-analytics](spark-sql-analytics.ipynb) tutorial notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data-exploration-v3io-frames-n-pandas\"></a>\n",
    "### Exploring Data Using V3IO Frames and pandas DataFrames\n",
    "\n",
    "Iguazio's V3IO Frames open-source data-access library provides a unified high-performance DataFrames API for accessing NoSQL, stream, and time-series data in the platform's data store.\n",
    "These DataFrames can also be used to analyze the data with pandas. \n",
    "For details and examples, see the [frames](frames.ipynb) tutorial notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data-exploration-sql\"></a>\n",
    "### Exploring Data Using SQL\n",
    "\n",
    "You can run SQL statements (`SELECT` only) on top of NoSQL tables in the platform's data store.\n",
    "To do this, you need to use the Jupyter `%sql` or `%%sql` IPython Jupyter magic followed by an SQL statement.\n",
    "The platform supports standard ANSI SQL semantics.\n",
    "Under the hood, the SQL statements are executed via [Presto](https://prestosql.io/), which is a distributed SQL engine designed from the ground up for fast analytics queries.\n",
    "\n",
    "In the example in the following cell, as a preparation for the SQL query, the **stocks.csv** file that was ingested to the **users/&lt;running user&gt;/examples** platform data-container directory in the previous [Ingesting Files from Amazon S3 to the Platform](#ingest-from-amazon-s3) example is written to a **stocks_example_tab** NoSQL table in the same directory.\n",
    "Then, an SQL `SELECT` query is run on this table.\n",
    "You can also find a similar example in the [getting-started example](#getting-started-example) in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use V3IO Frames to convert the CSV file that was ingested in the AWS S3 data-collection example to a NoSQL table.\n",
    "# NOTE: Make sure to first create a V3IO Frames service from the \"Services\" page of the platform dashboard, and run the\n",
    "# \"Ingesting Files from Amazon S3 to the Platform File System Using curl\" example to create users/$V3IO_USERNAME/examples/stocks.csv.\n",
    "import pandas as pd\n",
    "import v3io_frames as v3f\n",
    "import os\n",
    "\n",
    "# Create a V3IO Frames client for the \"users\" data container\n",
    "client = v3f.Client(\"framesd:8081\", container=\"users\")\n",
    "\n",
    "# Full CSV file path\n",
    "csv_path = os.path.join(\"/User\", \"examples\", \"stocks.csv\")\n",
    "# Relative NoSQL table path within the \"users\" container\n",
    "rel_nosql_table_path = os.path.join(os.getenv('V3IO_USERNAME'), \"examples\", \"stocks_example_tab\")\n",
    "\n",
    "# Read the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(csv_path, header=\"infer\")\n",
    "\n",
    "# Convert the CSV file to a NoSQL table\n",
    "client.write(\"kv\", rel_nosql_table_path, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>securitydesc</th>\n",
       "        <th>securitytype</th>\n",
       "        <th>time</th>\n",
       "        <th>isin</th>\n",
       "        <th>minprice</th>\n",
       "        <th>date</th>\n",
       "        <th>endprice</th>\n",
       "        <th>numberoftrades</th>\n",
       "        <th>mnemonic</th>\n",
       "        <th>currency</th>\n",
       "        <th>securityid</th>\n",
       "        <th>idx</th>\n",
       "        <th>maxprice</th>\n",
       "        <th>tradedvolume</th>\n",
       "        <th>startprice</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>XTR.DAX INCOME 1D</td>\n",
       "        <td>ETF</td>\n",
       "        <td>08:58</td>\n",
       "        <td>LU0838782315</td>\n",
       "        <td>105.16</td>\n",
       "        <td>2018-03-26</td>\n",
       "        <td>105.16</td>\n",
       "        <td>2</td>\n",
       "        <td>XDDX</td>\n",
       "        <td>EUR</td>\n",
       "        <td>2504277</td>\n",
       "        <td>7175</td>\n",
       "        <td>105.16</td>\n",
       "        <td>172</td>\n",
       "        <td>105.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>AMAZON.COM INC.    DL-,01</td>\n",
       "        <td>Common stock</td>\n",
       "        <td>08:54</td>\n",
       "        <td>US0231351067</td>\n",
       "        <td>1235.99</td>\n",
       "        <td>2018-03-26</td>\n",
       "        <td>1235.99</td>\n",
       "        <td>2</td>\n",
       "        <td>AMZ</td>\n",
       "        <td>EUR</td>\n",
       "        <td>2506427</td>\n",
       "        <td>6714</td>\n",
       "        <td>1235.99</td>\n",
       "        <td>5</td>\n",
       "        <td>1235.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>AURUBIS AG</td>\n",
       "        <td>Common stock</td>\n",
       "        <td>08:54</td>\n",
       "        <td>DE0006766504</td>\n",
       "        <td>66.82</td>\n",
       "        <td>2018-03-26</td>\n",
       "        <td>66.82</td>\n",
       "        <td>2</td>\n",
       "        <td>NDA</td>\n",
       "        <td>EUR</td>\n",
       "        <td>2505060</td>\n",
       "        <td>6673</td>\n",
       "        <td>66.82</td>\n",
       "        <td>127</td>\n",
       "        <td>66.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>WACKER CHEMIE        O.N.</td>\n",
       "        <td>Common stock</td>\n",
       "        <td>08:48</td>\n",
       "        <td>DE000WCH8881</td>\n",
       "        <td>136.45</td>\n",
       "        <td>2018-03-26</td>\n",
       "        <td>136.85</td>\n",
       "        <td>13</td>\n",
       "        <td>WCH</td>\n",
       "        <td>EUR</td>\n",
       "        <td>2504860</td>\n",
       "        <td>5893</td>\n",
       "        <td>136.85</td>\n",
       "        <td>1015</td>\n",
       "        <td>136.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>THYSSENKRUPP AG O.N.</td>\n",
       "        <td>Common stock</td>\n",
       "        <td>08:41</td>\n",
       "        <td>DE0007500001</td>\n",
       "        <td>21.45</td>\n",
       "        <td>2018-03-26</td>\n",
       "        <td>21.47</td>\n",
       "        <td>17</td>\n",
       "        <td>TKA</td>\n",
       "        <td>EUR</td>\n",
       "        <td>2505105</td>\n",
       "        <td>5180</td>\n",
       "        <td>21.47</td>\n",
       "        <td>9298</td>\n",
       "        <td>21.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>UNIPER SE  NA O.N.</td>\n",
       "        <td>Common stock</td>\n",
       "        <td>08:35</td>\n",
       "        <td>DE000UNSE018</td>\n",
       "        <td>24.17</td>\n",
       "        <td>2018-03-26</td>\n",
       "        <td>24.25</td>\n",
       "        <td>15</td>\n",
       "        <td>UN01</td>\n",
       "        <td>EUR</td>\n",
       "        <td>2504856</td>\n",
       "        <td>4415</td>\n",
       "        <td>24.25</td>\n",
       "        <td>3361</td>\n",
       "        <td>24.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>BRENNTAG AG NA O.N.</td>\n",
       "        <td>Common stock</td>\n",
       "        <td>08:33</td>\n",
       "        <td>DE000A1DAHH0</td>\n",
       "        <td>48.18</td>\n",
       "        <td>2018-03-26</td>\n",
       "        <td>48.18</td>\n",
       "        <td>2</td>\n",
       "        <td>BNR</td>\n",
       "        <td>EUR</td>\n",
       "        <td>2504453</td>\n",
       "        <td>4130</td>\n",
       "        <td>48.18</td>\n",
       "        <td>183</td>\n",
       "        <td>48.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>MUTARES AG</td>\n",
       "        <td>Common stock</td>\n",
       "        <td>08:30</td>\n",
       "        <td>DE000A0SMSH2</td>\n",
       "        <td>18.25</td>\n",
       "        <td>2018-03-26</td>\n",
       "        <td>18.35</td>\n",
       "        <td>2</td>\n",
       "        <td>MUX</td>\n",
       "        <td>EUR</td>\n",
       "        <td>2504399</td>\n",
       "        <td>3777</td>\n",
       "        <td>18.35</td>\n",
       "        <td>954</td>\n",
       "        <td>18.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>SYMRISE AG INH. O.N.</td>\n",
       "        <td>Common stock</td>\n",
       "        <td>08:28</td>\n",
       "        <td>DE000SYM9999</td>\n",
       "        <td>64.32</td>\n",
       "        <td>2018-03-26</td>\n",
       "        <td>64.32</td>\n",
       "        <td>3</td>\n",
       "        <td>SY1</td>\n",
       "        <td>EUR</td>\n",
       "        <td>2504852</td>\n",
       "        <td>3536</td>\n",
       "        <td>64.34</td>\n",
       "        <td>511</td>\n",
       "        <td>64.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>VOLKSWAGEN AG ST O.N.</td>\n",
       "        <td>Common stock</td>\n",
       "        <td>08:23</td>\n",
       "        <td>DE0007664005</td>\n",
       "        <td>157.2</td>\n",
       "        <td>2018-03-26</td>\n",
       "        <td>157.3</td>\n",
       "        <td>5</td>\n",
       "        <td>VOW</td>\n",
       "        <td>EUR</td>\n",
       "        <td>2505113</td>\n",
       "        <td>3016</td>\n",
       "        <td>157.3</td>\n",
       "        <td>377</td>\n",
       "        <td>157.3</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('XTR.DAX INCOME 1D', 'ETF', '08:58', 'LU0838782315', 105.16, '2018-03-26', 105.16, 2, 'XDDX', 'EUR', 2504277, 7175, 105.16, 172, 105.16),\n",
       " ('AMAZON.COM INC.    DL-,01', 'Common stock', '08:54', 'US0231351067', 1235.99, '2018-03-26', 1235.99, 2, 'AMZ', 'EUR', 2506427, 6714, 1235.99, 5, 1235.99),\n",
       " ('AURUBIS AG', 'Common stock', '08:54', 'DE0006766504', 66.82, '2018-03-26', 66.82, 2, 'NDA', 'EUR', 2505060, 6673, 66.82, 127, 66.82),\n",
       " ('WACKER CHEMIE        O.N.', 'Common stock', '08:48', 'DE000WCH8881', 136.45, '2018-03-26', 136.85, 13, 'WCH', 'EUR', 2504860, 5893, 136.85, 1015, 136.45),\n",
       " ('THYSSENKRUPP AG O.N.', 'Common stock', '08:41', 'DE0007500001', 21.45, '2018-03-26', 21.47, 17, 'TKA', 'EUR', 2505105, 5180, 21.47, 9298, 21.45),\n",
       " ('UNIPER SE  NA O.N.', 'Common stock', '08:35', 'DE000UNSE018', 24.17, '2018-03-26', 24.25, 15, 'UN01', 'EUR', 2504856, 4415, 24.25, 3361, 24.17),\n",
       " ('BRENNTAG AG NA O.N.', 'Common stock', '08:33', 'DE000A1DAHH0', 48.18, '2018-03-26', 48.18, 2, 'BNR', 'EUR', 2504453, 4130, 48.18, 183, 48.18),\n",
       " ('MUTARES AG', 'Common stock', '08:30', 'DE000A0SMSH2', 18.25, '2018-03-26', 18.35, 2, 'MUX', 'EUR', 2504399, 3777, 18.35, 954, 18.25),\n",
       " ('SYMRISE AG INH. O.N.', 'Common stock', '08:28', 'DE000SYM9999', 64.32, '2018-03-26', 64.32, 3, 'SY1', 'EUR', 2504852, 3536, 64.34, 511, 64.34),\n",
       " ('VOLKSWAGEN AG ST O.N.', 'Common stock', '08:23', 'DE0007664005', 157.2, '2018-03-26', 157.3, 5, 'VOW', 'EUR', 2505113, 3016, 157.3, 377, 157.3)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use Presto to query the NoSQL table that was created in the previous step\n",
    "presto_nosql_table_path = os.path.join('v3io.users.\"' + os.getenv('V3IO_USERNAME'), 'examples', 'stocks_example_tab\"')\n",
    "%sql select * from $presto_nosql_table_path limit 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"getting-started-example\"></a>\n",
    "## Data Collection and Exploration Getting-Started Example\n",
    "\n",
    "This section demonstrates a data collection, ingestion, and exploration flow.\n",
    "Follow the tutorial by running the code cells in order of appearance:\n",
    "- [Step #1](#getting-started-example-step-ingest-csv) &mdash; a CSV file is read from an Amazon S3 bucket and saved into an examples data-container directory using curl.\n",
    "  The examples directory is first created by using a file-system command.\n",
    "- [Step #2](#getting-started-example-step-convert-csv-to-nosql-table) &mdash; the ingested file is converted into a NoSQL table by using Spark DataFrames.\n",
    "- [Step #3](#getting-started-example-step-run-sql-queries) &mdash; a Presto SQL query is run on the NoSQL table.\n",
    "- [Step #4](#getting-started-example-step-convert-data-to-parquet) &mdash; the ingested CSV file is converted into a Parquet table by using Spark DataFrames.\n",
    "- [Step #5](#getting-started-example-step-browse-the-examples-dir) &mdash; the examples container directory is browsed by using local and Hadoop file-system commands.\n",
    "- At the end of the flow, you can optionally [delete](#getting-started-example-deleting-data) the examples directory using a file-system command.\n",
    "\n",
    "You can find more information about this sample flow in the [Converting a CSV File to a NoSQL Table](https://www.iguazio.com/docs/latest-release/tutorials/getting-started/ingest-n-consume-files/#convert-csv-to-nosql) platform quick-start tutorial.\n",
    "\n",
    "> **Tip:** You can also browse the files and directories that you write to the \"users\" container in this tutorial from the platform dashboard: in the side navigation menu, select **Data**, and then select the **users** container from the table. On the container data page, select the **Browse** tab, and then use the side directory-navigation tree to browse the directories. Selecting a file or directory in the browse table displays its metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"getting-started-example-step-ingest-csv\"></a>\n",
    "### Step 1: Ingest a Sample CSV File from Amazon S3\n",
    "\n",
    "Use `curl` to download a sample stocks-data CSV file from the [Iguazio sample data-set](http://iguazio-sample-data.s3.amazonaws.com/) public Amazon S3 bucket.\n",
    "For additional public data sets, check out [Registry of Open Data on AWS](https://registry.opendata.aws/).\n",
    "\n",
    "> **NOTE:** All the platform tutorial notebook examples store the data in an **examples** directory in the running-user directory of the predefined \"users\" container &mdash; **users/&lt;running user&gt;/examples**.\n",
    "> The running-user directory is automatically created by the Jupyter Notebook service.\n",
    "> The `V3IO_HOME` environment variable is used to reference the **users/&lt;running user&gt;** directory.\n",
    "> To save the data to a different root container directory or to a different container, you need to specify the data path in the local file-system commands as `/v3io/<container name>/<data path>`, and in Spark DataFrames or Hadoop FS commands as a fully qualified path of the format `v3io://<container name>/<table path>`.\n",
    "> For more information, see the [v3io-mount](#v3io-mount) and [running-user directory](#running-user-dir) information [Jupyter Notebook Basics](#jupyter-notebook-basics) section of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  861k  100  861k    0     0   592k      0  0:00:01  0:00:01 --:--:--  592k\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "DIR_PATH=\"/User/examples/\" # <=> \"/v3io/${V3IO_HOME}/examples/\" or \"/v3io/users/${V3IO_USERNAME}/examples/\"\n",
    "CSV_PATH=\"${DIR_PATH}stocks.csv\"\n",
    "\n",
    "# Create the examples directory\n",
    "mkdir -p ${DIR_PATH}\n",
    "\n",
    "# Download a sample stocks CSV file from the Iguazio sample data-set Amazon S3 bucket to the examples directory\n",
    "curl -L \"iguazio-sample-data.s3.amazonaws.com/2018-03-26_BINS_XETR08.csv\" > ${CSV_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"getting-started-example-step-convert-csv-to-nosql-table\"></a>\n",
    "### Step 2: Convert the Sample CSV File to a NoSQL Table\n",
    "\n",
    "Read the sample **stocks.csv** file that you downloaded and ingested in the previous step into a Spark DataFrame, and write the data in NoSQL format to a new \"stocks_tab\" table in the same container directory (**users/&lt;running user&gt;/examples/stocks_tab**). \n",
    "\n",
    "> **Note**\n",
    "> - To use the Iguazio Spark Connector, set the DataFrame's data-source format to `io.iguaz.v3io.spark.sql.kv`.\n",
    "> - The data path in the Spark DataFrame is specified by using the `V3IO_HOME_URL` environment variable, which is set to `v3io://users/<running user>`.\n",
    ">   See the [running-user directory](#running-user-dir) information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+--------------------+------------+--------+----------+-------------------+-----+----------+--------+--------+--------+------------+--------------+\n",
      "|        ISIN|Mnemonic|        SecurityDesc|SecurityType|Currency|SecurityID|               Date| Time|StartPrice|MaxPrice|MinPrice|EndPrice|TradedVolume|NumberOfTrades|\n",
      "+------------+--------+--------------------+------------+--------+----------+-------------------+-----+----------+--------+--------+--------+------------+--------------+\n",
      "|CH0038389992|    BBZA|BB BIOTECH NAM.  ...|Common stock|     EUR|   2504244|2018-03-26 00:00:00|08:00|      56.4|    56.4|    56.4|    56.4|         320|             4|\n",
      "|CH0038863350|    NESR|NESTLE NAM.      ...|Common stock|     EUR|   2504245|2018-03-26 00:00:00|08:00|     63.04|   63.06|    63.0|   63.06|         314|             3|\n",
      "|LU0378438732|    C001|COMSTAGE-DAX UCIT...|         ETF|     EUR|   2504271|2018-03-26 00:00:00|08:00|    113.42|  113.42|  113.42|  113.42|         100|             1|\n",
      "|LU0411075020|    DBPD|XTR.SHORTDAX X2 D...|         ETF|     EUR|   2504272|2018-03-26 00:00:00|08:00|    4.1335|  4.1335|  4.1295|    4.13|      102993|             8|\n",
      "|LU0838782315|    XDDX|   XTR.DAX INCOME 1D|         ETF|     EUR|   2504277|2018-03-26 00:00:00|08:00|    105.14|   105.2|  105.14|   105.2|         239|             3|\n",
      "|DE000A0DJ6J9|     S92|SMA SOLAR TECHNOL.AG|Common stock|     EUR|   2504287|2018-03-26 00:00:00|08:00|     55.65|   55.65|   55.65|   55.65|         543|             3|\n",
      "|DE000A0D6554|    NDX1|      NORDEX SE O.N.|Common stock|     EUR|   2504290|2018-03-26 00:00:00|08:00|     8.182|    8.21|   8.174|    8.21|       10941|             8|\n",
      "|DE000A0F5UE8|    EXXU|IS.DJ CHINA OFFS....|         ETF|     EUR|   2504302|2018-03-26 00:00:00|08:00|     47.52|   47.52|   47.52|   47.52|         420|             1|\n",
      "|DE000A0HN5C6|    DWNI|DEUTSCHE WOHNEN S...|Common stock|     EUR|   2504314|2018-03-26 00:00:00|08:00|      36.2|   36.24|    36.2|   36.24|         580|             5|\n",
      "|DE000A0LD2U1|     AOX|ALSTRIA OFFICE RE...|Common stock|     EUR|   2504379|2018-03-26 00:00:00|08:00|     12.25|   12.25|   12.25|   12.25|        1728|             3|\n",
      "|DE000A0LR936|     ST5|           STEICO SE|Common stock|     EUR|   2504382|2018-03-26 00:00:00|08:00|     22.35|   22.35|   22.35|   22.35|         334|             1|\n",
      "|DE000A0MZ4B0|     DLX|DELIGNIT AG      ...|Common stock|     EUR|   2504390|2018-03-26 00:00:00|08:00|      10.3|    10.3|    10.3|    10.3|         850|             1|\n",
      "|DE000A0Q8NC8|    ETLX|ETFS DAXGL.G.MIN....|         ETF|     EUR|   2504397|2018-03-26 00:00:00|08:00|    17.844|  17.844|  17.838|  17.838|        3085|             5|\n",
      "|DE000A0V9YU8|    4RT3|ETFS COM.SEC.DZ08...|         ETC|     EUR|   2504421|2018-03-26 00:00:00|08:00|    5.8895|  5.8895|  5.8895|  5.8895|           0|             1|\n",
      "|DE000A0WMPJ6|    AIXA|  AIXTRON SE NA O.N.|Common stock|     EUR|   2504428|2018-03-26 00:00:00|08:00|      16.8|    16.8|   16.75|  16.755|        3329|             8|\n",
      "|DE000A0Z2XN6|     RIB|RIB SOFTWARE SE  ...|Common stock|     EUR|   2504436|2018-03-26 00:00:00|08:00|     24.66|   24.66|   24.52|   24.52|       11741|            29|\n",
      "|DE000A0Z2ZZ5|    FNTN|  FREENET AG NA O.N.|Common stock|     EUR|   2504438|2018-03-26 00:00:00|08:00|     24.41|   24.42|   24.41|   24.42|         695|             6|\n",
      "|DE000A1A6V48|     KSC|      KPS AG NA O.N.|Common stock|     EUR|   2504441|2018-03-26 00:00:00|08:00|      9.15|    9.15|    9.15|    9.15|          73|             1|\n",
      "|DE000A1DAHH0|     BNR| BRENNTAG AG NA O.N.|Common stock|     EUR|   2504453|2018-03-26 00:00:00|08:00|     48.14|   48.14|   48.14|   48.14|         185|             2|\n",
      "|DE000A1EWWW0|     ADS|   ADIDAS AG NA O.N.|Common stock|     EUR|   2504471|2018-03-26 00:00:00|08:00|     196.3|  196.35|   196.3|  196.35|         591|            12|\n",
      "+------------+--------+--------------------+------------+--------+----------+-------------------+-----+----------+--------+--------+--------+------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- ISIN: string (nullable = true)\n",
      " |-- Mnemonic: string (nullable = true)\n",
      " |-- SecurityDesc: string (nullable = true)\n",
      " |-- SecurityType: string (nullable = true)\n",
      " |-- Currency: string (nullable = true)\n",
      " |-- SecurityID: integer (nullable = true)\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Time: string (nullable = true)\n",
      " |-- StartPrice: double (nullable = true)\n",
      " |-- MaxPrice: double (nullable = true)\n",
      " |-- MinPrice: double (nullable = true)\n",
      " |-- EndPrice: double (nullable = true)\n",
      " |-- TradedVolume: integer (nullable = true)\n",
      " |-- NumberOfTrades: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Example diretory path - a <running user>/examples directory in the \"users\" container\n",
    "dir_path = os.path.join(os.getenv(\"V3IO_HOME_URL\"), \"examples\")\n",
    "# CSV file path\n",
    "csv_path = os.path.join(dir_path, \"stocks.csv\")\n",
    "# NoSQL table path\n",
    "nosql_table_path = os.path.join(dir_path, \"stocks_tab\")\n",
    "\n",
    "# Create a new Spark session\n",
    "spark = SparkSession.builder.appName(\"Iguazio data ingestion and preparation getting-started example\").getOrCreate()\n",
    "\n",
    "# Read the sample CSV file into a Spark DataFrame, and let Spark infer the schema of the data\n",
    "df = spark.read.option(\"header\", \"true\").csv(csv_path, inferSchema=\"true\")\n",
    "\n",
    "# Show the DataFrame data\n",
    "df.show()\n",
    "\n",
    "# Write the DataFrame data to a NoSQL table in a platform data container.\n",
    "# Define the \"ISIN\" column (attribute) as the table's primary key.\n",
    "df.write.format(\"io.iguaz.v3io.spark.sql.kv\").mode(\"append\") \\\n",
    "    .option(\"key\", \"ISIN\").option(\"allow-overwrite-schema\", \"true\") \\\n",
    "    .save(nosql_table_path)\n",
    "\n",
    "# Display the table schema:\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"getting-started-example-step-run-sql-queries\"></a>\n",
    "### Step 3: Run Interactive SQL Queries\n",
    "\n",
    "Use the `%sql` Jupyter magic to run an SQL queries on the \"stocks_tab\" table that was created in the previous step.\n",
    "(The queries is processed using Presto.)\n",
    "The example runs a `SELECT` query that reads the first ten table items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "presto_nosql_table_path = os.path.join('v3io.users.\"' + os.getenv('V3IO_USERNAME'), 'examples', 'stocks_tab\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>securitydesc</th>\n",
       "        <th>securitytype</th>\n",
       "        <th>time</th>\n",
       "        <th>isin</th>\n",
       "        <th>minprice</th>\n",
       "        <th>date</th>\n",
       "        <th>endprice</th>\n",
       "        <th>numberoftrades</th>\n",
       "        <th>mnemonic</th>\n",
       "        <th>currency</th>\n",
       "        <th>securityid</th>\n",
       "        <th>maxprice</th>\n",
       "        <th>tradedvolume</th>\n",
       "        <th>startprice</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>LINDE AG O.N.</td>\n",
       "        <td>Common stock</td>\n",
       "        <td>08:04</td>\n",
       "        <td>DE0006483001</td>\n",
       "        <td>168.4</td>\n",
       "        <td>2018-03-26 00:00:00.000</td>\n",
       "        <td>168.4</td>\n",
       "        <td>1</td>\n",
       "        <td>LIN</td>\n",
       "        <td>EUR</td>\n",
       "        <td>2505043</td>\n",
       "        <td>168.4</td>\n",
       "        <td>74</td>\n",
       "        <td>168.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>IMMOFINANZ AG INH.</td>\n",
       "        <td>Common stock</td>\n",
       "        <td>08:54</td>\n",
       "        <td>AT0000809058</td>\n",
       "        <td>2.084</td>\n",
       "        <td>2018-03-26 00:00:00.000</td>\n",
       "        <td>2.084</td>\n",
       "        <td>1</td>\n",
       "        <td>IMO</td>\n",
       "        <td>EUR</td>\n",
       "        <td>2504179</td>\n",
       "        <td>2.084</td>\n",
       "        <td>1000</td>\n",
       "        <td>2.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>CLIQ DIGITAL AG  O.N.</td>\n",
       "        <td>Common stock</td>\n",
       "        <td>08:08</td>\n",
       "        <td>DE000A0HHJR3</td>\n",
       "        <td>5.74</td>\n",
       "        <td>2018-03-26 00:00:00.000</td>\n",
       "        <td>5.74</td>\n",
       "        <td>1</td>\n",
       "        <td>CLIQ</td>\n",
       "        <td>EUR</td>\n",
       "        <td>2504310</td>\n",
       "        <td>5.74</td>\n",
       "        <td>196</td>\n",
       "        <td>5.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>ISHARES SLI UCITS ETF DE</td>\n",
       "        <td>ETF</td>\n",
       "        <td>08:56</td>\n",
       "        <td>DE0005933964</td>\n",
       "        <td>80.6</td>\n",
       "        <td>2018-03-26 00:00:00.000</td>\n",
       "        <td>80.6</td>\n",
       "        <td>1</td>\n",
       "        <td>EXI1</td>\n",
       "        <td>EUR</td>\n",
       "        <td>2504990</td>\n",
       "        <td>80.6</td>\n",
       "        <td>75</td>\n",
       "        <td>80.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>ISHSV.MSCI W.EUR HGD ACC</td>\n",
       "        <td>ETF</td>\n",
       "        <td>08:00</td>\n",
       "        <td>IE00B441G979</td>\n",
       "        <td>48.902</td>\n",
       "        <td>2018-03-26 00:00:00.000</td>\n",
       "        <td>48.902</td>\n",
       "        <td>1</td>\n",
       "        <td>IBCH</td>\n",
       "        <td>EUR</td>\n",
       "        <td>2505679</td>\n",
       "        <td>48.902</td>\n",
       "        <td>1368</td>\n",
       "        <td>48.902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>STEINHOFF INT.HLDG.EO-,50</td>\n",
       "        <td>Common stock</td>\n",
       "        <td>08:00</td>\n",
       "        <td>NL0011375019</td>\n",
       "        <td>0.236</td>\n",
       "        <td>2018-03-26 00:00:00.000</td>\n",
       "        <td>0.2393</td>\n",
       "        <td>42</td>\n",
       "        <td>SNH</td>\n",
       "        <td>EUR</td>\n",
       "        <td>2506267</td>\n",
       "        <td>0.2405</td>\n",
       "        <td>220338</td>\n",
       "        <td>0.2378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>SOURCE-S.ST.E.600OP.PHG A</td>\n",
       "        <td>ETF</td>\n",
       "        <td>08:06</td>\n",
       "        <td>IE00B5MTZ595</td>\n",
       "        <td>449.55</td>\n",
       "        <td>2018-03-26 00:00:00.000</td>\n",
       "        <td>449.55</td>\n",
       "        <td>1</td>\n",
       "        <td>SC04</td>\n",
       "        <td>EUR</td>\n",
       "        <td>2505707</td>\n",
       "        <td>449.55</td>\n",
       "        <td>38</td>\n",
       "        <td>449.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>DEMIRE DT.MTS.RE AG</td>\n",
       "        <td>Common stock</td>\n",
       "        <td>08:19</td>\n",
       "        <td>DE000A0XFSF0</td>\n",
       "        <td>4.42</td>\n",
       "        <td>2018-03-26 00:00:00.000</td>\n",
       "        <td>4.42</td>\n",
       "        <td>2</td>\n",
       "        <td>DMRE</td>\n",
       "        <td>EUR</td>\n",
       "        <td>2504430</td>\n",
       "        <td>4.42</td>\n",
       "        <td>25075</td>\n",
       "        <td>4.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>EPIGENOMICS AG NA O.N.</td>\n",
       "        <td>Common stock</td>\n",
       "        <td>08:07</td>\n",
       "        <td>DE000A11QW50</td>\n",
       "        <td>3.78</td>\n",
       "        <td>2018-03-26 00:00:00.000</td>\n",
       "        <td>3.78</td>\n",
       "        <td>1</td>\n",
       "        <td>ECX</td>\n",
       "        <td>EUR</td>\n",
       "        <td>2504547</td>\n",
       "        <td>3.78</td>\n",
       "        <td>100</td>\n",
       "        <td>3.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>LYX.EURO ST.50D.(2X)L. A</td>\n",
       "        <td>ETF</td>\n",
       "        <td>08:08</td>\n",
       "        <td>FR0010468983</td>\n",
       "        <td>23.02</td>\n",
       "        <td>2018-03-26 00:00:00.000</td>\n",
       "        <td>23.02</td>\n",
       "        <td>1</td>\n",
       "        <td>LYMZ</td>\n",
       "        <td>EUR</td>\n",
       "        <td>2506387</td>\n",
       "        <td>23.02</td>\n",
       "        <td>2800</td>\n",
       "        <td>23.02</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('LINDE AG O.N.', 'Common stock', '08:04', 'DE0006483001', 168.4, '2018-03-26 00:00:00.000', 168.4, 1, 'LIN', 'EUR', 2505043, 168.4, 74, 168.4),\n",
       " ('IMMOFINANZ AG INH.', 'Common stock', '08:54', 'AT0000809058', 2.084, '2018-03-26 00:00:00.000', 2.084, 1, 'IMO', 'EUR', 2504179, 2.084, 1000, 2.084),\n",
       " ('CLIQ DIGITAL AG  O.N.', 'Common stock', '08:08', 'DE000A0HHJR3', 5.74, '2018-03-26 00:00:00.000', 5.74, 1, 'CLIQ', 'EUR', 2504310, 5.74, 196, 5.74),\n",
       " ('ISHARES SLI UCITS ETF DE', 'ETF', '08:56', 'DE0005933964', 80.6, '2018-03-26 00:00:00.000', 80.6, 1, 'EXI1', 'EUR', 2504990, 80.6, 75, 80.6),\n",
       " ('ISHSV.MSCI W.EUR HGD ACC', 'ETF', '08:00', 'IE00B441G979', 48.902, '2018-03-26 00:00:00.000', 48.902, 1, 'IBCH', 'EUR', 2505679, 48.902, 1368, 48.902),\n",
       " ('STEINHOFF INT.HLDG.EO-,50', 'Common stock', '08:00', 'NL0011375019', 0.236, '2018-03-26 00:00:00.000', 0.2393, 42, 'SNH', 'EUR', 2506267, 0.2405, 220338, 0.2378),\n",
       " ('SOURCE-S.ST.E.600OP.PHG A', 'ETF', '08:06', 'IE00B5MTZ595', 449.55, '2018-03-26 00:00:00.000', 449.55, 1, 'SC04', 'EUR', 2505707, 449.55, 38, 449.55),\n",
       " ('DEMIRE DT.MTS.RE AG', 'Common stock', '08:19', 'DE000A0XFSF0', 4.42, '2018-03-26 00:00:00.000', 4.42, 2, 'DMRE', 'EUR', 2504430, 4.42, 25075, 4.42),\n",
       " ('EPIGENOMICS AG NA O.N.', 'Common stock', '08:07', 'DE000A11QW50', 3.78, '2018-03-26 00:00:00.000', 3.78, 1, 'ECX', 'EUR', 2504547, 3.78, 100, 3.78),\n",
       " ('LYX.EURO ST.50D.(2X)L. A', 'ETF', '08:08', 'FR0010468983', 23.02, '2018-03-26 00:00:00.000', 23.02, 1, 'LYMZ', 'EUR', 2506387, 23.02, 2800, 23.02)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql select * from $presto_nosql_table_path limit 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>_col0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>737</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(737,)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql select count(*) from $presto_nosql_table_path "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"getting-started-example-step-convert-data-to-parquet\"></a>\n",
    "### Step 4: Convert the Data to a Parquet Table\n",
    "\n",
    "Use a Spark DataFrame `write` command to write the data in the Spark DaraFrame &mdash; which was created from the CSV file and used to create the NoSQL table in [Step 2](#getting-started-example-step-convert-csv-to-nosql-table) &mdash; to a new **users/&lt;running user&gt;/examples/stocks_prqt** Parquet table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the DataFrame data that was read from the CSV file in Step 2 to a Parquet table in a platform data container\n",
    "prqt_table_path = os.path.join(dir_path, \"stocks_prqt\")\n",
    "df.write.mode('overwrite').parquet(prqt_table_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"getting-started-example-step-browse-the-examples-dir\"></a>\n",
    "### Step 5: Browse the Example Container Directory\n",
    "\n",
    "Use a file-system bash-shell command to list the contents of the **users/&lt;running user&gt;/examples** data-container directory to which all the ingested data in the previous steps were saved.\n",
    "You should see in this directory the **stocks.csv** file, **stocks_tab** NoSQL table directory, and **stocks_prqt** Parquet table directory that you created in the previous steps.\n",
    "The following cells demonstrate how to issue the same command using the local file system and using Hadoop FS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\n",
      "drwxrwxr-x 2 50 nogroup      0 Mar 10 07:43 stocks_example_tab\n",
      "-rw-r--r-- 1 50 nogroup 882055 Mar 10 07:45 stocks.csv\n",
      "drwxrwxrwx 2 50 nogroup      0 Mar 10 07:47 stocks_tab\n",
      "drwxr-xr-x 2 50 nogroup      0 Mar 10 07:49 stocks_prqt\n",
      "-rw-r--r-- 1 50 nogroup 150996 Mar 10 08:38 parquet_example\n",
      "-rw-rw-r-- 1 50 nogroup 113629 Mar 10 08:48 userdata1.parquet\n",
      "drwxrwxr-x 2 50 nogroup      0 Mar 10 08:50 spark-output\n",
      "drwxrwxr-x 2 50 nogroup      0 Mar 10 08:51 multiple-parquet-files\n",
      "drwxrwxr-x 2 50 nogroup      0 Mar 10 09:18 family\n",
      "drwxrwxr-x 2 50 nogroup      0 Mar 10 09:19 family1\n",
      "drwxrwxr-x 2 50 nogroup      0 Mar 10 09:19 family2\n",
      "-rw-rw-r-- 1 50 nogroup    475 Mar 10 09:43 mLines.json\n",
      "-rw-rw-r-- 1 50 nogroup 131745 Mar 10 09:46 CoffeeTime.jpg\n",
      "drwxrwxrwx 2 50 nogroup      0 Mar 10 09:47 mytable\n",
      "drwxrwxrwx 2 50 nogroup      0 Mar 10 09:48 stocks_kv\n",
      "drwxrwxrwx 2 50 nogroup      0 Mar 10 09:48 stocks_kv_partition\n",
      "drwxr-xr-x 2 50 nogroup      0 Mar 10 09:52 stocks_parq\n",
      "drwxrwxrwx 2 50 nogroup      0 Mar 10 09:52 weather\n",
      "-rw-r--r-- 1 50 nogroup 882055 Mar 10 11:29 demo.csv\n",
      "drwxrwxr-x 2 50 nogroup      0 Mar 10 11:37 csvs\n"
     ]
    }
   ],
   "source": [
    "# List the contents of the users/<running user>/examples directory using a local file-system command\n",
    "!ls -lrt /User/examples\n",
    "# The following are equivalent commands that demonstrate different ways to reference your user home directory:\n",
    "#!ls -lrt /v3io/${V3IO_HOME}/examples\n",
    "#!ls -lrt /v3io/users/${V3IO_USERNAME}/examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 items\n",
      "-rw-r--r--   1 55 root     882055 2020-01-16 09:00 v3io://users/iguazio/examples/stocks.csv\n",
      "drwxrwxr-x   - 55 root          0 2020-01-16 09:00 v3io://users/iguazio/examples/stocks_example_tab\n",
      "drwxr-xr-x   - 55 root          0 2020-01-16 09:01 v3io://users/iguazio/examples/stocks_prqt\n",
      "drwxrwxrwx   - 55 root          0 2020-01-16 09:01 v3io://users/iguazio/examples/stocks_tab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20/01/16 09:01:24 INFO slf_4j.Slf4jLogger: Slf4jLogger started\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "# List the contents of the users/<running user>/examples directory using an Hadoop FS command\n",
    "hadoop fs -ls ${V3IO_HOME_URL}/examples\n",
    "# The following are equivalent commands that demonstrate different ways to reference your user home directory:\n",
    "#hadoop fs -ls v3io://${V3IO_HOME}/examples\n",
    "#hadoop fs -ls v3io://users/${V3IO_USERNAME}/examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cleanup\"></a>\n",
    "## Cleanup\n",
    "\n",
    "Prior to exiting, release disk space, computation, and memory resources consumed by the active session:\n",
    "\n",
    "- [Delete Data](#delete-data)\n",
    "- [Release Spark Resources](#release-spark-resources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"delete-data\"></a>\n",
    "### Delete Data\n",
    "\n",
    "Optionally delete  any of the directories or files that you created.\n",
    "See the instructions in the [Creating and Deleting Container Directories](https://www.iguazio.com/docs/latest-release/tutorials/getting-started/containers/#create-delete-container-dirs) tutorial.\n",
    "The following example uses a local file-system command to delete the entire contents of the **users/&lt;running user&gt;/examples** directory that was created in this example, but not the directory itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the contents of the examples directory:\n",
    "#!rm -rf /User/examples/*\n",
    "# You can also delete the examples directory iteself (and all its contents):\n",
    "#!rm -rf /User/examples/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"release-spark-resources\"></a>\n",
    "### Release Spark Resources\n",
    "\n",
    "When you're done, run the following command to stop your Spark session and release its computation and memory resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
